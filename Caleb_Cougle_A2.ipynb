{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2c10ab",
   "metadata": {},
   "source": [
    "## Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682dff57",
   "metadata": {},
   "source": [
    "##### 🥣 Selenium & BeautifulSoup: Extract info from web sources\n",
    "##### 🌩 URL Manipulation: Bypass CloudFlare with string formatters\n",
    "##### 🔁 For Loops: Iterate through nested elements\n",
    "##### 🧽 Pandas: Clean and manipulate data\n",
    "##### 📈 Data Aggregation: Final quality check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e96f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** Import the required packages **** #\n",
    "from selenium import webdriver  # <---- library\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # <---- library\n",
    "from selenium.webdriver.common.by import By  # <---- library\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.webdriver.common import keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "from time import sleep  # <---- time delay for loading as to not break the server\n",
    "from selenium.webdriver.chrome.service import Service  # <---- library\n",
    "\n",
    "driver_service = Service(\n",
    "    executable_path='/Users/calebcougle/PY/chromedriver'\n",
    ")  # <---- establish service with the path of the driver\n",
    "from selenium.webdriver.common.keys import Keys  # <---- library\n",
    "import pandas as pd  # <---- library\n",
    "from bs4 import BeautifulSoup  #<--- This is beautiufl soup to extract the info we need to look better\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import random\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05219f03",
   "metadata": {},
   "source": [
    "##### 👉 URL manipulation using string formatters to avoid CloudFlare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a08c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** the below cell sets up the functions and variables used for the Webscraping **** # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cda395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** Variables that define our 'flight' search **** #\n",
    "# These variables will be used as parameters to manipulate the webJet URL\n",
    "urldate = ''  #<--- initialize a variable to use later\n",
    "\n",
    "destination = 'Sydney'\n",
    "destination_code = 'SYD'\n",
    "origin = 'Brisbane'\n",
    "origin_code = 'BNE'\n",
    "now = datetime.now()\n",
    "\n",
    "\n",
    "# **** This function will create the date format required for the url **** #\n",
    "def url_date_maker(\n",
    "        from_ymd,\n",
    "        to_ymd):  #<--- This function will take an INT in YYYYMMMDD format\n",
    "    global urldate  #<--- Assign global varaible\n",
    "    from_ymd = pd.to_datetime(\n",
    "        from_ymd, format=\"%Y%m%d\")  #<--- Take int, convert to Time series\n",
    "    to_ymd = pd.to_datetime(\n",
    "        to_ymd, format=\"%Y%m%d\")  #<--- Take int, convert to Time series\n",
    "    days_between = pd.date_range(\n",
    "        from_ymd, to_ymd - timedelta(days=1),\n",
    "        freq='d')  #<--- list all the dates between the two\n",
    "    urldate = days_between.strftime(\n",
    "        '%Y%m%d'\n",
    "    )  #<--- Convert date back to a string and assign to web_date Variable\n",
    "\n",
    "\n",
    "# Call the function with these dates YYYMMDD\n",
    "url_date_maker(20221116, 2022016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc49976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** initialize variables to store data from a function  **** #\n",
    "now = datetime.now()\n",
    "lst_prices = []\n",
    "lst_carrier = []\n",
    "flight_depart = []\n",
    "flight_arrive = []\n",
    "cabin_class = []\n",
    "departure_date = []\n",
    "cabin_class = []\n",
    "time = random.randint(\n",
    "    4, 8)  #<--- Using this random INT pass into sleep() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6f834",
   "metadata": {},
   "source": [
    "#####  👉  Selenium Web Driver and BeautifulSoup to find elements and extract info from the source\n",
    "#####  👉 Using for Loops to iterate through BeautifulSoup objects to find nested elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeda0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** initialize variables to store data from a function  **** #\n",
    "\n",
    "\n",
    "def web_scraper(web_date, desination, destination_code, origin, origin_code):\n",
    "    global lst_prices  #<-- Assign global variables to access outside function\n",
    "    global lst_carrier\n",
    "    global flight_depart\n",
    "    global flight_arrive\n",
    "    global departure_date\n",
    "    global cabin_class\n",
    "    i = 0  #<-- Use as counter and to iterate through dates in urldate\n",
    "    days = len(urldate) - 1  #<-- This is to get index\n",
    "    while i <= days:\n",
    "        url2 = 'https://services.webjet.com.au/web/flights/matrix/?Adults=1&Children=0&Infants=0&TravelClass=Economy&GeoCategory=AUDomestic&TripType=Oneway&OneWay={origin_code}-{origin_code}-{destination_code}-{destination_code}-{web_date}&CityFrom={origin}&CityTo={destination}&CityCodeFrom={origin_code}&CityCodeTo={destination_code}'.format(\n",
    "            destination=destination,\n",
    "            destination_code=destination_code,\n",
    "            origin=origin,\n",
    "            origin_code=origin_code,\n",
    "            web_date=urldate[i])\n",
    "        driver = webdriver.Chrome(service=driver_service)\n",
    "        sleep(\n",
    "            time\n",
    "        )  #<-- This stops activity, to prevent me from being 'locked out'\n",
    "        page = driver.get(url2)\n",
    "        sleep(time)\n",
    "        flight_boxes = driver.find_elements(By.ID, \"main-container\")\n",
    "        sleep(time)\n",
    "        for WebElement in flight_boxes:\n",
    "            elementHTML = WebElement.get_attribute('outerHTML')\n",
    "            elementSoup = BeautifulSoup(elementHTML,\n",
    "                                        'html.parser')  #<-- Get the HTML\n",
    "            for date in elementSoup.find_all(\n",
    "                    \"div\", {'class': 'departure-info'}\n",
    "            ):  #<---- This is used to find the information inside each flight, this could all be done maybe without indents\n",
    "                for resultrow in elementSoup.find_all(\n",
    "                        \"tr\", {'class': 'result-row'\n",
    "                               }):  #<-- ... contains table row results\n",
    "                    for time_arrive in resultrow.find(\n",
    "                            \"span\",\n",
    "                        {'class': 'time-arrive'\n",
    "                         }): #<-- ... contains the arrival time\n",
    "                        for time_depart in resultrow.find(\n",
    "                                \"span\",\n",
    "                            {'class': 'time-depart'\n",
    "                             }):  #<-- ... contains the departure time\n",
    "                            for airline in resultrow.find(\n",
    "                                    \"span\", {'class': 'small-carrier-logo'\n",
    "                                             }):  #<-- ... contains the airline\n",
    "                                for price in resultrow.find_all(\n",
    "                                        \"span\",\n",
    "                                    {\"class\": \"price-text\"\n",
    "                                     }):  #<-- ... contains the price text\n",
    "                                    for cabin in price.find_parents(\n",
    "                                            \"td\",\n",
    "                                        {\"class\": \"fare-price\"\n",
    "                                         }):  #<-- ... contains fare-type info\n",
    "                                        lst_prices.append(\n",
    "                                            str(price.string[1:])\n",
    "                                        )  #<-- append the price to lst prices variable as a string object, then convert a python string\n",
    "                                        lst_carrier.append(\n",
    "                                            str(airline['alt'])\n",
    "                                        )  #<-- the alt text to string (which contains the airline call sign), then convert to python string and append\n",
    "                                        flight_depart.append(\n",
    "                                            str(time_depart.string)\n",
    "                                        )  #<-- convert the webelement to string, then convert to python string and append to flight_depart variable\n",
    "                                        flight_arrive.append(\n",
    "                                            str(time_arrive.string)\n",
    "                                        )  #<-- ... to flight_arrive variable\n",
    "                                        departure_date.append(\n",
    "                                            str(date.string)\n",
    "                                        )  #<-- ... to flight_arrive variable\n",
    "                                        cabin_class.append(\n",
    "                                            str(cabin.attrs['data-testid'])\n",
    "                                        )  #<-- ... to cabin_class variable\n",
    "        i += 1  #<-- ... add to counter\n",
    "        driver.quit(\n",
    "        )  #<-- ... I had close and start the session to overcome CloudFlare bot managment lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae346df",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scraper(urldate,'Sydney','SYD','Brisbane','BNE') #<-- ... Call the function with these arguments. NB// They aren't very user friendly parameters, but I fix this)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c304ffd",
   "metadata": {},
   "source": [
    "#####  👉 Quality checking as the program progresses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6654ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(lst_prices)\n",
    "print(lst_prices)\n",
    "print(lst_carrier)\n",
    "print(flight_arrive)\n",
    "print(flight_depart)\n",
    "print(departure_date)\n",
    "print(cabin_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7debc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(departure_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** Initilise the DF's to store function data **** #\n",
    "df_cost = pd.DataFrame()  #<-- ... initilise the DF's\n",
    "df_carrier = pd.DataFrame()\n",
    "df_cabin = pd.DataFrame()\n",
    "df_dep_t = pd.DataFrame()\n",
    "df_arrv_t = pd.DataFrame()\n",
    "df_dep_date = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ca055",
   "metadata": {},
   "source": [
    "#####  👉 Pandas library to store, clean and manipulate Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f387849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** A dataframe creating function  **** #\n",
    "# I wanted the ability to manipulate and clean data automatically so the program can be used on other routes/ dates etc\n",
    "\n",
    "\n",
    "def create_dataframes(\n",
    "    dep_date, dep_t, arrv_t, carrier, cost, cabin\n",
    "):  #<-- ... these parameters relate directly to the lists created in the scrape function\n",
    "\n",
    "    global df_cost, df_carrier, df_cabin, df_dep_t, df_arrv_t, df_dep_date, df_flight_data  #<-- ... make the DataFrames global to acess outside the function\n",
    "    df_cost = pd.DataFrame(cost)\n",
    "    df_carrier = pd.DataFrame(carrier)\n",
    "    df_cabin = pd.DataFrame(cabin)\n",
    "    df_dep_t = pd.DataFrame(dep_t)\n",
    "    df_arrv_t = pd.DataFrame(arrv_t)\n",
    "    df_dep_date = pd.DataFrame(dep_date)\n",
    "\n",
    "    df_flight_data = pd.concat(  #<-- ... Create a Dataframe with all the merged Data from the scrape\n",
    "        [df_dep_date, df_dep_t, df_arrv_t, df_carrier, df_cabin, df_cost],\n",
    "        axis=1,  #<-- ... Merge the DataFrames\n",
    "        ignore_index=True)  #<-- ... this didn't seem to do anything lol\n",
    "\n",
    "    column_names = {  #<-- ... A dict of column names to pass\n",
    "        0: 'departure_date',\n",
    "        1: 'departure_time',\n",
    "        2: 'arrival_time',\n",
    "        3: 'airline',\n",
    "        4: 'fare_type',\n",
    "        5: 'price ($)'\n",
    "    }\n",
    "\n",
    "    df_flight_data.rename(columns=column_names,\n",
    "                          inplace=True)  #<-- ... Change our DF into\n",
    "\n",
    "    dates_col = pd.DatetimeIndex(\n",
    "        df_flight_data['departure_date'])  #<-- ... Convert departure date using DateTimeIndex and store in dates_col variable\n",
    "    df_flight_data.insert(\n",
    "        0, 'year', dates_col.year\n",
    "    )  #<-- ... From the dates_col, take the year and insert it at index 0 ( to make it the 4th col)\n",
    "    df_flight_data.insert(\n",
    "        0, 'month', dates_col.month\n",
    "    )  #<-- ... Take the month and insert it at index 0 (to make it the 3th col)\n",
    "    df_flight_data.insert(\n",
    "        0, 'day', dates_col.day\n",
    "    )  #<-- ... Take the day and insert it at index 0 (to make it the 2nd col)\n",
    "    df_flight_data.insert(\n",
    "        0, 'day_in_week', dates_col.day_name()\n",
    "    )  #<-- ... Take the day of week and insert it at index 0 (to make it the 1st col)\n",
    "\n",
    "    df_flight_data['arrival_time'] = pd.to_datetime(\n",
    "        df_flight_data['arrival_time'], format=\"%I:%M %p\"\n",
    "    ).dt.time  #<--- Take the string arrival time as \"Hours, mins, am/pm\" and convert to Date Time \".dt.time\" is to get rid of the annoying \"1900-01-01\"\n",
    "    df_flight_data['departure_time'] = pd.to_datetime(\n",
    "        df_flight_data['departure_time'], format=\"%I:%M %p\").dt.time\n",
    "\n",
    "    # **** Clean the data  **** #\n",
    "    df_flight_data.drop('departure_date', axis=1,\n",
    "                        inplace=True)  #<--- Drop this column\n",
    "    df_flight_data.replace(',', '', regex=True,\n",
    "                           inplace=True)  #<-- remove commas\n",
    "    df_flight_data.replace('cell-', '', regex=True,\n",
    "                           inplace=True)  #<-- remove 'cell'\n",
    "    df_flight_data.replace(\n",
    "        'QF', 'Qantas', regex=True,\n",
    "        inplace=True)  #<-- Change call sign to Airline and regex + inplace 🚩🚩🚩\n",
    "    df_flight_data.replace('VA', 'Virgin', regex=True, inplace=True)  #<-- ...\n",
    "    df_flight_data.replace('ZL', 'Rex', regex=True, inplace=True)  #<-- ...\n",
    "    df_flight_data.replace('JQ', 'JetStar', regex=True, inplace=True)  #<-- ...\n",
    "    df_flight_data = df_flight_data.astype({\n",
    "        'fare_type': 'string',\n",
    "        'airline': 'string',\n",
    "        'price ($)': 'int'\n",
    "    })  #<--convert using astype to appropriate data structure\n",
    "\n",
    "\n",
    "create_dataframes(\n",
    "    departure_date, flight_depart, flight_arrive, lst_carrier, lst_prices,\n",
    "    cabin_class\n",
    ")  #<-- Call the function to create dataframes using the arguments that hold the scraped data\n",
    "print(df_flight_data)\n",
    "print(df_cost, df_carrier, df_cabin, df_dep_t, df_arrv_t, df_dep_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7fde0",
   "metadata": {},
   "source": [
    "#####  👉 ✈️Pre-flight check of data for accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** Pre-flight check for quality  **** #\n",
    "# another function so I could use this multiple times for desired route\n",
    "# False = PASS\n",
    "# True = FAIL\n",
    "def check_results(data_frame):\n",
    "    print(\"**** IMPORTANT INFO ****\\nFalse = PASSED\\nTrue = FAILED\\n********\")\n",
    "    print(\"****Duplicate Check:****\\n\", data_frame.duplicated().any())  #\n",
    "    print(\"****Null Check:****\\n\", data_frame.isnull().any())  \n",
    "    print(\"****NA Check:****\\n\", data_frame.isna().any())  \n",
    "    print(\"****Data Types Info:****\\n\", data_frame.info())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results(\n",
    "    df_flight_data\n",
    ")  #<--Call function with merged and cleaned dataframe df_flight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the median price of fare-type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad00355",
   "metadata": {},
   "source": [
    "#####  👉 Preliminary data aggregation to as a quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snap shot of the Data Frame\n",
    "df_flight_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014adfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Count of Fare Type in  % \n",
    "df_flight_data['day'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_data['fare_type'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8e262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c709ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Count of Departure time in  % \n",
    "df_flight_data['departure_time'].value_counts(normalize=True).head(10)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_data['arrival_time'].value_counts(normalize=True).head(10)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13733eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_data['airline'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6ba79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6293f1bd",
   "metadata": {},
   "source": [
    "### Thank-you 👋🏼✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ba867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d694faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56a735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b668037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed1192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df43a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efcce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad10f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flightDataScrape(web_date):\n",
    "    url2 = f'https://services.webjet.com.au/web/flights/matrix/?Adults=1&Children=0&Infants=0&TravelClass=Economy&GeoCategory=AUDomestic&TripType=Oneway&OneWay={origin_code}-{origin_code}-{destination_code}-{destination_code}-{web_date}&CityFrom={origin}&CityTo={destination}&CityCodeFrom={origin_code}&CityCodeTo={destination_code}'.format(\n",
    "    destination=destination,\n",
    "    destination_code=destination_code,\n",
    "    origin=origin,\n",
    "    origin_code=origin_code,\n",
    "    web_date=web_date)\n",
    "    counter = 0 \n",
    "    lst_prices = []\n",
    "    lst_carrier = []\n",
    "    flight_depart = []\n",
    "    flight_arrive = []\n",
    "    cabin_class = []\n",
    "    departure_date = []  #<--- these could be dictionaries\n",
    "    cabin_class = []\n",
    "\n",
    "    for WebElement in flight_boxes:\n",
    "        elementHTML = WebElement.get_attribute('outerHTML')\n",
    "        elementSoup = BeautifulSoup(elementHTML, 'html.parser')\n",
    "\n",
    "        for date in elementSoup.find_all(\"div\", {'class': 'departure-info'}):  #<---- This is used to find the information inside each flight, this could all be done maybe without indents\n",
    "            for resultrow in elementSoup.find_all(\"tr\", {'class': 'result-row'}):\n",
    "                for time_arrive in resultrow.find(\"span\",{'class': 'time-arrive'}):\n",
    "                    for time_depart in resultrow.find(\"span\",{'class': 'time-depart'}):\n",
    "                        for airline in resultrow.find(\"span\", {'class': 'small-carrier-logo'}):\n",
    "                            for price in resultrow.find_all(\"span\", {\"class\": \"price-text\"}):\n",
    "                                for cabin in price.find_parents(\"td\", {\"class\": \"fare-price\"}):\n",
    "                                    lst_prices.append(price.string[1:])  #<--- this was previous way to make the dollar sign go away lol\n",
    "                                    lst_carrier.append(airline['alt'])\n",
    "                                    flight_depart.append(time_depart.string)\n",
    "                                    flight_arrive.append(time_arrive.string)\n",
    "                                    departure_date.append(str(date.string))\n",
    "                                    cabin_class.append(cabin.attrs['data-testid'])\n",
    "                                    sleep(time)\n",
    "                                    counter += 1\n",
    "    print(counter)\n",
    "print(\"i'm done\")\n",
    "\n",
    "flightDataScrape(20221113)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
